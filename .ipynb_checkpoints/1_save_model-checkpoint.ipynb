{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160daf33-7f69-4587-b30d-b87d9038a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, fsspec, filelock, huggingface_hub\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.2 huggingface_hub-0.30.2 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad765da3-1c0a-4e20-a0d8-0270e37115d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nabei-tengteng\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a72a0a7-eeb3-4654-9a2c-92b65508967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 16 05:52:52 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   38C    P0             27W /   70W |   13415MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A              42      C   /opt/app-root/bin/python3.11          13412MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1276f926-0395-4f9c-ba05-96b3e626a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib64/python3.11/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m258.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-25.0.1\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.37.34-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.37.34-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
      "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib64/python3.11/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/app-root/lib64/python3.11/site-packages (from botocore) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.17.0)\n",
      "Downloading boto3-1.37.34-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.37.34-py3-none-any.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m392.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.37.34 botocore-1.37.34 jmespath-1.0.1 s3transfer-0.11.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9609dc7b-c620-419f-8787-ea92555bd551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas (from -r requirements.txt (line 2))\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 3))\n",
      "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 13))\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting nltk (from -r requirements.txt (line 14))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sentence-transformers (from -r requirements.txt (line 17))\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers (from -r requirements.txt (line 18))\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate (from -r requirements.txt (line 19))\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 25)) (4.67.1)\n",
      "Collecting python-dotenv (from -r requirements.txt (line 26))\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain (from -r requirements.txt (line 29))\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting torch (from -r requirements.txt (line 32))\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 2))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 2))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r requirements.txt (line 13))\n",
      "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 13))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 13))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click (from nltk->-r requirements.txt (line 14))\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk->-r requirements.txt (line 14))\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers->-r requirements.txt (line 17)) (0.30.2)\n",
      "Collecting Pillow (from sentence-transformers->-r requirements.txt (line 17))\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers->-r requirements.txt (line 17)) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 18))\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers->-r requirements.txt (line 18))\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.11/site-packages (from accelerate->-r requirements.txt (line 19)) (6.1.1)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain->-r requirements.txt (line 29))\n",
      "  Downloading langchain_core-0.3.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain->-r requirements.txt (line 29))\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain->-r requirements.txt (line 29))\n",
      "  Downloading langsmith-0.3.31-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain->-r requirements.txt (line 29))\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->-r requirements.txt (line 29))\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting networkx (from torch->-r requirements.txt (line 32))\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch->-r requirements.txt (line 32))\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->-r requirements.txt (line 32))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.51->langchain->-r requirements.txt (line 29))\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.51->langchain->-r requirements.txt (line 29))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 29)) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 29))\n",
      "  Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 29))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 29))\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 29))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 29))\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 29))\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 18)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 18)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 18)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 18)) (2025.1.31)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 29))\n",
      "  Downloading greenlet-3.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 32)) (3.0.2)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 29)) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 29)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/app-root/lib64/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 29)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/app-root/lib64/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain->-r requirements.txt (line 29)) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/app-root/lib64/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 29)) (1.3.1)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m175.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m271.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m210.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m435.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m644.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m172.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m264.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m240.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m154.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m685.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m187.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m213.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m194.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m251.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m165.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m138.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m196.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m189.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m228.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading langchain_core-0.3.52-py3-none-any.whl (433 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.31-py3-none-any.whl (358 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m468.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m286.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m283.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m333.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m414.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m433.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m722.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m698.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, pytz, nvidia-cusparselt-cu12, mpmath, zstandard, tzdata, typing-inspection, threadpoolctl, tenacity, sympy, safetensors, regex, python-dotenv, pydantic-core, Pillow, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, jsonpatch, joblib, greenlet, click, annotated-types, SQLAlchemy, scipy, requests-toolbelt, pydantic, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, tokenizers, scikit-learn, nvidia-cusolver-cu12, langsmith, transformers, torch, langchain-core, sentence-transformers, langchain-text-splitters, accelerate, langchain\n",
      "Successfully installed Pillow-11.2.1 SQLAlchemy-2.0.40 accelerate-1.6.0 annotated-types-0.7.0 click-8.1.8 greenlet-3.2.0 joblib-1.4.2 jsonpatch-1.33 langchain-0.3.23 langchain-core-0.3.52 langchain-text-splitters-0.3.8 langsmith-0.3.31 mpmath-1.3.0 networkx-3.4.2 nltk-3.9.1 numpy-2.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 orjson-3.10.16 pandas-2.2.3 pydantic-2.11.3 pydantic-core-2.33.1 python-dotenv-1.1.0 pytz-2025.2 regex-2024.11.6 requests-toolbelt-1.0.0 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-4.1.0 sympy-1.13.1 tenacity-9.1.2 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.6.0 transformers-4.51.3 triton-3.2.0 typing-inspection-0.4.0 tzdata-2025.2 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6e7b3-4c40-4289-b540-99b62bf213de",
   "metadata": {},
   "source": [
    "## Snapshot Download of Granite Model\n",
    "\n",
    "Download full repo to prepare for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b727f656-e9c4-4eab-a134-fe26f369d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️  Downloading model 'ibm-granite/granite-3.2-8b-instruct' to './granite-3.2-8b-instruct' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/huggingface_hub/file_download.py:933: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n",
      "Fetching 15 files: 100%|██████████| 15/15 [02:16<00:00,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model downloaded to: /opt/app-root/src/rag-with-elasticsearch/granite-3.2-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading granite model\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_id = \"ibm-granite/granite-3.2-8b-instruct\"\n",
    "local_path = \"./granite-3.2-8b-instruct\"\n",
    "\n",
    "print(f\"⬇️  Downloading model '{model_id}' to '{local_path}' ...\")\n",
    "local_path = snapshot_download(repo_id=model_id, local_dir=local_path, local_dir_use_symlinks=False)\n",
    "print(f\"✅ Model downloaded to: {local_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed40e34-6afd-4737-801d-1bc8dfd6e17e",
   "metadata": {},
   "source": [
    "## Quantizing Granite Model\n",
    "\n",
    "Helps to reduce memory and hardware requirements of granite model (albeit with a small accuracy loss).\n",
    "\n",
    "### **Cancelled because quantization is not supported for granite using GPU yet**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6574abd1-9a1b-4bd6-b2e0-d318b9469fa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoAWQForCausalLM' from 'awq' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mawq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoAWQForCausalLM\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./granite-3.2-8b-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoAWQForCausalLM' from 'awq' (unknown location)"
     ]
    }
   ],
   "source": [
    "# from awq import AutoAWQForCausalLM\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# model_path = \"./granite-3.2-8b-instruct\"\n",
    "# output_path = \"./granite-8b-awq-int8\"\n",
    "\n",
    "# # Load model and tokenizer\n",
    "# model = AutoAWQForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# # INT8 quantization\n",
    "# model.quantize(\n",
    "#     bits=8,                  # ✅ INT8\n",
    "#     sym=True,                # Symmetric quantization\n",
    "#     per_channel=True,        # Higher accuracy\n",
    "#     damp_percent=0.01,       # Optional stabilization\n",
    "#     group_size=128           # Same structure as GPTQ\n",
    "# )\n",
    "\n",
    "# # Save the quantized model\n",
    "# model.save_quantized(output_path)\n",
    "# tokenizer.save_pretrained(output_path)\n",
    "\n",
    "# print(f\"✅ AWQ INT8 quantized model saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86219291-a816-4f92-84d0-989a77068e92",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9507bbfc-cb55-4c92-a70b-26edad39e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 12.22it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are you?\n",
      "\n",
      "I am an assistant designed to help answer your questions and provide information.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"ibm-granite/granite-3.2-8b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Convert your chat-style messages into a single prompt string\n",
    "prompt = \"Who are you?\"\n",
    "\n",
    "response = pipe(prompt, max_new_tokens=128, do_sample=True)\n",
    "print(response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64977b75-2205-4463-b265-466549d135f9",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e7f534c-c728-482e-9db8-fe9d4f0e1323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nabei-tengteng\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6134b45-95b2-436b-a544-3db1b6590d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "\n",
    "# Set your variables (do NOT hardcode tokens in real production — use dotenv or CI secrets)\n",
    "os.environ[\"HF_USERNAME\"] = \"nabei-tengteng\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a933d922-767e-4299-9757-c2244913808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'granite-3.2-8b-instruct' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "username = os.environ[\"HF_USERNAME\"]\n",
    "token = os.environ[\"HF_TOKEN\"]\n",
    "\n",
    "# git_repo = f\"https://{username}:{token}@huggingface.co/ibm-granite/granite-3.2-8b-instruct\"\n",
    "# !git clone $git_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4525dc5-68a3-447b-b96e-4a9bde302d6b",
   "metadata": {},
   "source": [
    "## Saving model in Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4587e5b-3677-4ebc-8839-ee50ec0b036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpdesk-chatbot-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Retrieve AWS credentials and S3 connection details from environment variables\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')\n",
    "\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c2c818-f93a-4fce-aef0-89360e3ad7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading granite-3.2-8b-instruct/added_tokens.json to s3://helpdesk-chatbot-data/models/granite-model/added_tokens.json\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/added_tokens.json\n",
      "Uploading granite-3.2-8b-instruct/merges.txt to s3://helpdesk-chatbot-data/models/granite-model/merges.txt\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/merges.txt\n",
      "Uploading granite-3.2-8b-instruct/model-00002-of-00004.safetensors to s3://helpdesk-chatbot-data/models/granite-model/model-00002-of-00004.safetensors\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model-00002-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/README.md to s3://helpdesk-chatbot-data/models/granite-model/README.md\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/README.md\n",
      "Uploading granite-3.2-8b-instruct/tokenizer_config.json to s3://helpdesk-chatbot-data/models/granite-model/tokenizer_config.json\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/tokenizer_config.json\n",
      "Uploading granite-3.2-8b-instruct/generation_config.json to s3://helpdesk-chatbot-data/models/granite-model/generation_config.json\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/generation_config.json\n",
      "Uploading granite-3.2-8b-instruct/model.safetensors.index.json to s3://helpdesk-chatbot-data/models/granite-model/model.safetensors.index.json\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model.safetensors.index.json\n",
      "Uploading granite-3.2-8b-instruct/model-00004-of-00004.safetensors to s3://helpdesk-chatbot-data/models/granite-model/model-00004-of-00004.safetensors\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model-00004-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/model-00003-of-00004.safetensors to s3://helpdesk-chatbot-data/models/granite-model/model-00003-of-00004.safetensors\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model-00003-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/tokenizer.json to s3://helpdesk-chatbot-data/models/granite-model/tokenizer.json\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/tokenizer.json\n",
      "Uploading granite-3.2-8b-instruct/model-00001-of-00004.safetensors to s3://helpdesk-chatbot-data/models/granite-model/model-00001-of-00004.safetensors\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model-00001-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/vocab.json to s3://helpdesk-chatbot-data/models/granite-model/vocab.json\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/vocab.json\n",
      "Uploading granite-3.2-8b-instruct/special_tokens_map.json to s3://helpdesk-chatbot-data/models/granite-model/special_tokens_map.json\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/special_tokens_map.json\n",
      "Uploading granite-3.2-8b-instruct/config.json to s3://helpdesk-chatbot-data/models/granite-model/config.json\n",
      "✅ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/config.json\n",
      "✅ Upload completed.\n",
      "\n",
      "📦 Objects in S3 under 'models/granite-model':\n",
      "models/granite-model/README.md\n",
      "models/granite-model/added_tokens.json\n",
      "models/granite-model/config.json\n",
      "models/granite-model/generation_config.json\n",
      "models/granite-model/merges.txt\n",
      "models/granite-model/model-00001-of-00004.safetensors\n",
      "models/granite-model/model-00002-of-00004.safetensors\n",
      "models/granite-model/model-00003-of-00004.safetensors\n",
      "models/granite-model/model-00004-of-00004.safetensors\n",
      "models/granite-model/model.safetensors.index.json\n",
      "models/granite-model/special_tokens_map.json\n",
      "models/granite-model/tokenizer.json\n",
      "models/granite-model/tokenizer_config.json\n",
      "models/granite-model/vocab.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "\n",
    "\n",
    "local_model_dir = \"granite-3.2-8b-instruct\"  # Path to your local model directory\n",
    "s3_prefix = \"models/granite-model\"   # Desired path in S3 bucket\n",
    "\n",
    "# === Initialize session and resource ===\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "\n",
    "def should_upload(file_path):\n",
    "    \"\"\"\n",
    "    Determine if a file should be uploaded (skip .git and hidden files).\n",
    "    \"\"\"\n",
    "    # Skip hidden files and folders (like .git, .DS_Store)\n",
    "    parts = file_path.split(os.sep)\n",
    "    for part in parts:\n",
    "        if part.startswith('.'):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def upload_file_to_s3(local_file_path, s3_key):\n",
    "    \"\"\"\n",
    "    Uploads a single file to S3.\n",
    "    \"\"\"\n",
    "    print(f\"Uploading {local_file_path} to s3://{bucket_name}/{s3_key}\")\n",
    "    bucket.upload_file(local_file_path, s3_key)\n",
    "    print(f\"✅ Uploaded to s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "\n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    \"\"\"\n",
    "    Recursively uploads a directory to S3, skipping unwanted files.\n",
    "    \"\"\"\n",
    "    found_files = False\n",
    "\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        # Modify dirs in-place to skip hidden folders\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "\n",
    "        for filename in files:\n",
    "            if filename.startswith('.'):\n",
    "                continue  # Skip hidden files\n",
    "\n",
    "            local_path = os.path.join(root, filename)\n",
    "            if not should_upload(local_path):\n",
    "                continue  # Skip unwanted files\n",
    "\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            upload_file_to_s3(local_path, s3_key)\n",
    "            found_files = True\n",
    "\n",
    "    if not found_files:\n",
    "        print(\"🚨 No valid files found to upload. Check your directory and filters!\")\n",
    "    else:\n",
    "        print(\"✅ Upload completed.\")\n",
    "\n",
    "\n",
    "def list_objects(prefix):\n",
    "    \"\"\"\n",
    "    Lists all objects in the S3 bucket with a given prefix.\n",
    "    \"\"\"\n",
    "    print(f\"\\n📦 Objects in S3 under '{prefix}':\")\n",
    "    for obj in bucket.objects.filter(Prefix=prefix):\n",
    "        print(obj.key)\n",
    "\n",
    "\n",
    "# === Run Upload ===\n",
    "upload_directory_to_s3(local_model_dir, s3_prefix)\n",
    "\n",
    "# === List uploaded objects ===\n",
    "list_objects(s3_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab303d-718d-472f-9300-c7e5318ab8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
