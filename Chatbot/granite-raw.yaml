apiVersion: modelmesh-serving.opendatahub.io/v1alpha1
kind: ServedModel
metadata:
  name: granite-8b-instruct
  namespace: predictive-wb
spec:
  modelFormat:
    name: huggingface
  storage:
    key: minio-dc
    path: models/granite-model
  inferenceService:
    name: llm-predictor
  requirements:
    minResources:
      cpu: "4"
      memory: "16Gi"
    accelerators:
      nvidia.com/gpu: 1
