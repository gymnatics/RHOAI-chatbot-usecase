{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24763475a3d8998c",
   "metadata": {},
   "source": [
    "<h1>Model Inference with RAG</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c004acc-13cd-4917-8480-592c7c2d623b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Change that following variable settings match your deployed model's *Inference endpoint*. for example: \n",
    "\n",
    "```\n",
    "infer_endpoint = \"https://model-vllm.apps.clusterx.sandboxx.opentlc.com\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e51a248-1ca8-496a-9fe3-9306b1974b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from file 3_RAG_with_Elastic\n",
    "# client = Elasticsearch(['https://elasticsearch-sample-elasticsearch.apps.rosa-t59w8.oufo.p1.openshiftapps.com'], basic_auth=('elastic', '1rdzVXU8i8F9T8hs1p6c78d6'), verify_certs=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eadce4d-0b69-4f0a-aff7-5f888e85e4f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h1>Model Inference</h1>\n",
    "\n",
    "<h3>using: /v1/completions endpoint</h3>\n",
    "<h4>*More for Single-shot prompts, single-turn Q&A or document completion</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de65d02-84a6-4cff-882e-551cdd42b486",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "infer_endpoint = \"http://model-predictor.minio.svc.cluster.local:8080\" #Change infer endpoint here\n",
    "infer_url = f\"{infer_endpoint}/v1/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc76424-b6cb-4ac9-a4d5-54a3da27d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"id\":\"model\",\"object\":\"model\",\"created\":1745399297,\"owned_by\":\"vllm\",\"root\":\"/mnt/models\",\"parent\":null,\"max_model_len\":4096,\"permission\":[{\"id\":\"modelperm-6efda1d1ab644349b109915e5b0913d7\",\"object\":\"model_permission\",\"created\":1745399297,\"allow_create_engine\":false,\"allow_sampling\":true,\"allow_logprobs\":true,\"allow_search_indices\":false,\"allow_view\":true,\"allow_fine_tuning\":false,\"organization\":\"*\",\"group\":null,\"is_blocking\":false}]}]}"
     ]
    }
   ],
   "source": [
    "# get the model name \n",
    "# for testing only\n",
    "!curl http://model-predictor.minio.svc.cluster.local:8080/v1/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bdff6a7-03c9-418d-ae55-22efbbc32cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenShift is a container application platform built around a core of Docker container packaging and Kubernetes orchestration. It provides an enterprise-grade container platform with originating technology contributions from Red Hat, Google, and others in the open source community.\n",
      "\n",
      "Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications. It groups containers that make up an application into logical units for easy management and discovery.\n",
      "\n",
      "In summary, OpenShift is a distribution of Kubernetes with additional features and tools tailored for enterprise use cases, while Kubernetes is the underlying orchestration engine for managing containers at scale.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# Test for hyperparameter tuning \n",
    "payload = {\n",
    "    \"model\": \"model\",\n",
    "    \"prompt\": \"What's the difference between OpenShift and Kubernetes?\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.3, # Controls randomness, lower temp for factuality \n",
    "    \"top_p\": 1,\n",
    "    \"n\": 1, # Number of completions to generate\n",
    "    \"repetition_penalty\": 1.1, # Penalize repeated tokens (1 = no penalty)\n",
    "    \"presence_penalty\": 0.2, # Discourage mentioning same concepts again\n",
    "    \"frequency_penalty\": 0.2, # Discourage repeating the *same words* too frequently\n",
    "    \"stream\": False # If True, stream tokens back (like a live typewriter)\n",
    "}\n",
    "\n",
    "response = requests.post(infer_url, json=payload)\n",
    "\n",
    "# prints the whole response json\n",
    "# print(response.json())\n",
    "\n",
    "output_body = response.json()\n",
    "generated_response = output_body['choices'][0]['text']\n",
    "print(generated_response.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa17d77-2268-4551-bcdb-355608dd0fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenShift is an open-source container application platform based on Kubernetes. It provides a more user-friendly and feature-rich environment for developers and operations teams, including built-in CI/CD pipelines, a web-based console, and integrated monitoring tools. Kubernetes, on the other hand, is a container orchestration system that automates the deployment, scaling, and management of containerized applications. It requires more manual configuration and integration with other tools.\n"
     ]
    }
   ],
   "source": [
    "# Test for hyperparameter tuning \n",
    "payload = {\n",
    "    \"model\": \"model\",\n",
    "    \"prompt\": \"What's the difference between OpenShift and Kubernetes?\",\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "response = requests.post(infer_url, json=payload)\n",
    "\n",
    "# prints the whole response json\n",
    "# print(response.json())\n",
    "\n",
    "output_body = response.json()\n",
    "generated_response = output_body['choices'][0]['text']\n",
    "print(generated_response.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61cf4b-12c7-45ab-bb8b-180bac0cdd4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h1>Model Inference</h1>\n",
    "\n",
    "<h3>using: /v1/chat/completions endpoint</h3>\n",
    "<h3>*More for chat-tuned, multi-turn conversations, model behaving like assistant</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea5b6587-e26d-4885-91a5-e774e479c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO DO into the Prompt Template\n",
    "# preserve messages history \n",
    "# keep older messages if they are essential for content \n",
    "# truncate long histories by summarizing/dropping older exchanges \n",
    "\n",
    "# Prompt token - is there a max? \n",
    "\n",
    "# create a Python class to connect to FE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1adf3582-4d44-4fd2-80f9-0fb79fca5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_endpoint = \"http://model-predictor.minio.svc.cluster.local:8080\" #Change infer endpoint here\n",
    "infer_url = f\"{infer_endpoint}/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d85782f-f1d6-40a7-b483-0098df7f5293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/SEAK_AI\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4360dbaf-baa5-41b5-9e68-078f3b9c0dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"id\":\"model\",\"object\":\"model\",\"created\":1745399306,\"owned_by\":\"vllm\",\"root\":\"/mnt/models\",\"parent\":null,\"max_model_len\":4096,\"permission\":[{\"id\":\"modelperm-85d97a29967141ffb8e2faef4ecfcde3\",\"object\":\"model_permission\",\"created\":1745399306,\"allow_create_engine\":false,\"allow_sampling\":true,\"allow_logprobs\":true,\"allow_search_indices\":false,\"allow_view\":true,\"allow_fine_tuning\":false,\"organization\":\"*\",\"group\":null,\"is_blocking\":false}]}]}"
     ]
    }
   ],
   "source": [
    "# get the model name \n",
    "# for testing only\n",
    "!curl http://model-predictor.minio.svc.cluster.local:8080/v1/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a68837a-cf3d-464b-9a9a-d816c55daca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenShift and Kubernetes are both container orchestration tools, but they have some key differences:\n",
      "\n",
      "1. **Base Technology**: Kubernetes is an open-source platform designed to automate deploying, scaling, and managing containerized applications. It groups containers that make up an application into logical units for easy management and discovery. On the other hand, OpenShift is a container application platform built on top of Kubernetes. It adds additional features and capabilities.\n",
      "\n",
      "2. **Ease of Use**: OpenShift is generally considered easier to use than raw Kubernetes because it includes a web console and automation features out of the box. This can be particularly beneficial for developers who may not have extensive experience with Kubernetes. \n",
      "\n",
      "3. **Additional Features**: OpenShift comes with several built-in features like integrated CI/CD pipelines (using tools such as Jenkins), a private registry for container images, operational safety through automated backups and self-healing, and more robust role-based access control (RBAC). These extra features aim to provide a complete development and operations environment for the enterprise.\n",
      "\n",
      "4. **Support and Services**: Red Hat offers official support for OpenShift, which can be crucial for businesses needing professional assistance. While Kubernetes has a large community providing support via various channels, direct technical support isn't guaranteed unless you opt for paid services from vendors like Red Hat or Google (with GKE - Google Kubernetes Engine).\n",
      "\n",
      "5. **Customization**: Since Kubernetes is more basic and modular, it allows for greater customization based on specific needs. OpenShift, while powerful, might limit certain advanced customizations due to its added layers of abstraction and pre-configured components.\n",
      "\n",
      "In summary, if you're looking for a more straightforward setup with additional enterprise-level features right away, OpenShift could be the better choice. If you prefer a leaner tool that you can customize extensively according to your requirements and don't mind setting up these additional elements yourself, then Kubernetes would be suitable.\n"
     ]
    }
   ],
   "source": [
    "user_question_one = \"What's the difference between OpenShift & Kubernetes?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a chat bot assistant for helping people with their queries.\"},\n",
    "    {\"role\": \"user\", \"content\": user_question_one}\n",
    "]\n",
    "\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"model\",\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.3, # Controls randomness, lower temp for factuality \n",
    "    \"top_p\": 1,\n",
    "    \"n\": 1, # Number of completions to generate\n",
    "    \"repetition_penalty\": 1.1, # Penalize repeated tokens (1 = no penalty)\n",
    "    \"presence_penalty\": 0.2, # Discourage mentioning same concepts again\n",
    "    \"frequency_penalty\": 0.2, # Discourage repeating the *same words* too frequently\n",
    "    \"stream\": False # If True, stream tokens back (like a live typewriter)\n",
    "}\n",
    "\n",
    "response = requests.post(infer_url, json=payload)\n",
    "\n",
    "# prints the whole response json\n",
    "# print(response.json())\n",
    "\n",
    "output_body = response.json()\n",
    "generated_response = output_body['choices'][0]['message']['content']\n",
    "print(generated_response.strip())\n",
    "\n",
    "# add to the messages list \n",
    "messages.append({\"role\": \"system\", \"content\": generated_response.strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d0596c-62e3-4b19-b54f-a85203d985b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to explain how you can implement Retrieval-Augmented Generation (RAG) using Elasticsearch as your vector database.\n",
      "\n",
      "Retrieval-Augented Generation (RAG) is a methodology that combines the power of retrieval systems with generative models. The idea is to retrieve relevant information from a large corpus of data and feed this information into a language model to generate human-like text. Hereâ€™s a simplified step-by-step guide on how to implement this using Elasticsearch as your vector database:\n",
      "\n",
      "1. **Data Preparation**: Firstly, you need to prepare your data. This involves tokenizing your documents and converting them into vectors using techniques like word embeddings (Word2Vec, GloVe), sentence embeddings (Sentence-BERT, Universal Sentence Encoder), or contextual embeddings (ELMo, BERT). These vectors will represent your documents in a high dimensional space where semantically similar texts are close together.\n",
      "\n",
      "2. **Indexing Documents in Elasticsearch**: Once you've converted your documents into vectors, you'll index these vectors alongside their corresponding document IDs in Elasticsearch. You can use the Elasticsearch's Vector Search API for this purpose, which allows you to store and query dense vectors.\n",
      "\n",
      "   ```json\n",
      "   PUT /my_index\n",
      "   {\n",
      "     \"settings\": {\n",
      "       \"number_of_shards\": 1,\n",
      "       \"number_of_replicas\": 0\n",
      "     },\n",
      "     \"mappings\": {\n",
      "       \"properties\": {\n",
      "         \"vector\": {\n",
      "           \"type\": \"dense_vector\",\n",
      "           \"dimensions\": 512\n",
      "         },\n",
      "         \"_id\": {\n",
      "           \"type\": \"keyword\"\n",
      "         }\n",
      "       }\n",
      "     }\n",
      "   }\n",
      "   \n",
      "   POST /my_index/_doc/1\n",
      "   {\n",
      "     \"vector\": [0.1, 0.2, 0.3],\n",
      "     \"_id\": \"doc1\"\n",
      "   }\n",
      "   ```\n",
      "   \n",
      "3. **Querying with Vector Similarity**: When you want to retrieve relevant documents for a given prompt, convert the prompt into a vector in the same way as your indexed documents. Then use Elasticsearch's `more_like_this` query or `script_score` function with cosine similarity measure to find the most similar vectors (and thus documents) in your index.\n",
      "\n",
      "   ```json\n",
      "   GET /my_index/_search\n",
      "   {\n",
      "     \"query\": {\n",
      "       \"function_score\": {\n",
      "         \"functions\": [\n",
      "           {\n",
      "             \"script_score\": {\n",
      "               \"script\": {\n",
      "                 \"source\": \"cosineSimilarity(params.queryVector, 'vector') + 1.0\",\n",
      "                 \"params\": {\n",
      "                   \"queryVector\": [0.4, 0.5, 0.6] // Your prompt vector here\n",
      "                 }\n",
      "               }\n",
      "             }\n",
      "           }\n",
      "         ],\n",
      "         \"field_value_factor\": {\"field\": \"vector\", \"factor\": 1.0},\n",
      "         \"score_mode\": \"sum\"\n",
      "       }\n",
      "     }\n",
      "   }\n",
      "   ```\n",
      "\n",
      "4. **Fine-tuning Language Model**: After retrieving relevant documents, feed these into a language model fine-tuned for generation tasks (like text summarization or question answering). Fine-tune it on your specific dataset so it knows how to utilize the retrieved information effectively.\n",
      "\n",
      "5. **Generation**: Finally, use the fine-tuned language model to generate text based on the retrieved documents and the initial input prompt.\n",
      "\n",
      "Remember that each step involves complex processes and considerations depending on your specific use case and dataset size. Also, keep in mind that working with vector databases requires careful handling of dimensionality and computational resources due to the high-dimensional nature of vector spaces. \n",
      "\n",
      "This is a high level overview and actual implementation might require deeper dives into each step mentioned above, especially when dealing with details related to machine learning model training and integration with search engines like Elasticsearch.\n"
     ]
    }
   ],
   "source": [
    "# ongoing conversations \n",
    "\n",
    "user_question_two = \"I'm interested in implementing AI with RAG approach, tell me more about how i can do it with elastic as the vector database\"\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_question_two})\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"model\",\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.3, # Controls randomness, lower temp for factuality \n",
    "    \"top_p\": 1,\n",
    "    \"n\": 1, # Number of completions to generate\n",
    "    \"repetition_penalty\": 1.1, # Penalize repeated tokens (1 = no penalty)\n",
    "    \"presence_penalty\": 0.2, # Discourage mentioning same concepts again\n",
    "    \"frequency_penalty\": 0.2, # Discourage repeating the *same words* too frequently\n",
    "    \"stream\": False # If True, stream tokens back (like a live typewriter)\n",
    "}\n",
    "\n",
    "response = requests.post(infer_url, json=payload)\n",
    "\n",
    "# prints the whole response json\n",
    "# print(response.json())\n",
    "\n",
    "output_body = response.json()\n",
    "generated_response = output_body['choices'][0]['message']['content']\n",
    "print(generated_response.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2a831-9d78-4159-b393-58865906f2a5",
   "metadata": {},
   "source": [
    "<h1>Create Embeddings in Elastic Vector Database</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577e04b8-11be-4c2a-a97e-b45e018127ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/app-root/lib64/python3.11/site-packages (3.1.1)\n",
      "Requirement already satisfied: elasticsearch in /opt/app-root/lib64/python3.11/site-packages (8.10.0)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers) (4.40.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers) (0.32.4)\n",
      "Requirement already satisfied: Pillow in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /opt/app-root/lib64/python3.11/site-packages (from elasticsearch) (8.17.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /opt/app-root/lib64/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2.2.1)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/app-root/lib64/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/app-root/lib64/python3.11/site-packages (from triton==3.3.1->torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib64/python3.11/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/app-root/lib64/python3.11/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/app-root/lib64/python3.11/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install dependencies & imports\n",
    "!pip install sentence-transformers elasticsearch pandas tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from tqdm import tqdm\n",
    "from elasticsearch.helpers import bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773470e5-bc8e-4f23-bd8b-b68e3961c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /opt/app-root/lib64/python3.11/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from kagglehub) (2.32.3)\n",
      "Collecting tqdm (from kagglehub)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, kagglehub\n",
      "Successfully installed kagglehub-0.3.12 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac7e7f1-f3de-47f2-865d-44bbe763d609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tobiasbueck/helpdesk-github-tickets\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d482934a-6c89-4fc9-b0f7-c448676dd479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   issue_id  answer_id author              creation_time  \\\n",
      "0    456983          0  almet  2010-12-05T17:31:55+00:00   \n",
      "1    456983          1  Gui13  2010-12-05T17:43:43+00:00   \n",
      "2    456983          2  almet  2010-12-05T17:45:28+00:00   \n",
      "3    456983          3  almet  2010-12-14T15:57:04+00:00   \n",
      "4    456983          4  Gui13  2010-12-21T21:02:19+00:00   \n",
      "\n",
      "                                          issue_body  \\\n",
      "0  Hey, Say I add an image in my article, giving ...   \n",
      "1  Hey, Say I add an image in my article, giving ...   \n",
      "2  Hey, Say I add an image in my article, giving ...   \n",
      "3  Hey, Say I add an image in my article, giving ...   \n",
      "4  Hey, Say I add an image in my article, giving ...   \n",
      "\n",
      "                                         answer_body  \n",
      "0  If we do add the SITEURL value, it can break b...  \n",
      "1  A bit hackish for sure, but I'm not yet good e...  \n",
      "2  okay, let's go for that so. Will do that when ...  \n",
      "3  arnaud is currently working on that, see his f...  \n",
      "4                     Should this bug be closed now?  \n",
      "\n",
      "\n",
      "['issue_id', 'answer_id', 'author', 'creation_time', 'issue_body', 'answer_body']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_helpdesk_data.csv\", low_memory=False)\n",
    "print(df.head())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "855b0992-a52a-4d8c-a13c-1a19506ca934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/SEAK_AI\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "321accf0-c0b0-4a7e-9c33-63f1494258f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing - create a smaller csv\n",
    "df = pd.read_csv(\"cleaned_helpdesk_data.csv\")\n",
    "# df_sample = df.head(100)\n",
    "# df_sample.to_csv(\"helpdesk_small_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fedfa2b-f61a-4257-bdce-92b30c071e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/elasticsearch/_sync/client/__init__.py:397: SecurityWarning: Connecting to 'https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com:443' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'elasticsearch-sample-es-default-0', 'cluster_name': 'elasticsearch-sample', 'cluster_uuid': 'S_nsm8kqSrye5fgJyJJpLw', 'version': {'number': '8.17.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '2b6a7fed44faa321997703718f07ee0420804b41', 'build_date': '2024-12-11T12:08:05.663969764Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "# elasticsearch client \n",
    "es = Elasticsearch(\n",
    "    hosts=[\"https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com\"], \n",
    "    basic_auth=('myadmin', 'newpassword123'), \n",
    "    verify_certs=False\n",
    ")\n",
    "print(es.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70712625-c421-4644-87f4-a407bc3d0eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 4.1.0, however, your version is 3.1.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   issue_id                                         issue_body  \\\n",
      "0    456983  Hey, Say I add an image in my article, giving ...   \n",
      "1    648603  if you render 5 templates deep, and that templ...   \n",
      "2    798136  I have an app which is using connect.vhost to ...   \n",
      "3    814067  Hello, There is a problem with the Pelican's l...   \n",
      "4    984126  Hi, I'm just about to migrate to pelican and f...   \n",
      "5    998441  Hi, I'm trying pelican (which is exactly what ...   \n",
      "6   2349963  The page about **data types** <link> mentions ...   \n",
      "7   2891909  I'd love support for additional Markdown file ...   \n",
      "8   3052375  SET in pelican.conf.py: `STATIC_PATHS = [\"imag...   \n",
      "9   3500667  When I create a post using Pelican, images app...   \n",
      "\n",
      "                                         answer_body  \n",
      "0  If we do add the SITEURL value, it can break b...  \n",
      "1  Having a similar issue when rendering partials...  \n",
      "2  Just so I can find it again (compare view is n...  \n",
      "3  Having a header like this one in _all_ pelican...  \n",
      "4  Hello, No, as far as i know, it's not supposed...  \n",
      "5  You've missed the blank line after the code-bl...  \n",
      "6  Hi, used to be 1GB, was later modified to 512M...  \n",
      "7  Thanks for the notice. I don't know if you're ...  \n",
      "8  I think it is, yes. The way static path and im...  \n",
      "9  I've tried something around this. When I wrote...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/elasticsearch/_sync/client/__init__.py:397: SecurityWarning: Connecting to 'https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com:443' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/tmp/ipykernel_67/1966566472.py:49: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es.indices.create(\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'elasticsearch-sample-es-default-0', 'cluster_name': 'elasticsearch-sample', 'cluster_uuid': 'S_nsm8kqSrye5fgJyJJpLw', 'version': {'number': '8.17.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '2b6a7fed44faa321997703718f07ee0420804b41', 'build_date': '2024-12-11T12:08:05.663969764Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings stored successfully in Elasticsearch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n"
     ]
    }
   ],
   "source": [
    "# LOGIC\n",
    "# ideally, all the contents of 'cleaned_body' field from the continous answer_ids grouped under the same issue_id should be in a single vector embedding \n",
    "\n",
    "# Load your job dataset\n",
    "# df = pd.read_csv(\"helpdesk_small_sample.csv\")\n",
    "\n",
    "# not all values in clean_body are strings, thus throwing TypeError if this line is not runned \n",
    "df[\"answer_body\"] = df[\"answer_body\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Group answers by issue_id and concatenate them in order\n",
    "grouped = (\n",
    "    df.sort_values(by=[\"issue_id\", \"answer_id\"])\n",
    "      .groupby(\"issue_id\")\n",
    "      .agg({\n",
    "          \"issue_body\": \"first\",\n",
    "          \"answer_body\": lambda x: \" \".join(x)\n",
    "      })\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(grouped.head(10))\n",
    "# Embedding Model \n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # faced out of memory error \n",
    "# model = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\", device=\"cuda\")  # lighter version\n",
    "model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device='cuda')\n",
    "\n",
    "# Combine issue_body and answer_body into a single string for embedding\n",
    "grouped[\"full_text\"] = grouped[\"issue_body\"] + \" \" + grouped[\"answer_body\"]\n",
    "\n",
    "# Generate embeddings\n",
    "grouped[\"embedding\"] = model.encode(grouped[\"full_text\"]).tolist()\n",
    "\n",
    "# grouped = df.sort_values(by=[\"issue_id\", \"answer_id\"]).groupby(\"issue_id\")[\"clean_body\"].apply(lambda texts: \" \".join(texts)).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# elasticsearch client \n",
    "es = Elasticsearch(\n",
    "    hosts=[\"https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com\"], \n",
    "    basic_auth=('myadmin', 'newpassword123'), \n",
    "    verify_certs=False\n",
    ")\n",
    "print(es.info())\n",
    "\n",
    "index_name = \"helpdesk-embeddings\"\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"issue_id\": {\"type\": \"keyword\"},\n",
    "                    \"issue_body\": {\"type\": \"text\"},\n",
    "                    \"answer_body\": {\"type\": \"text\"},\n",
    "                    \"embedding\": {\n",
    "                        \"type\": \"dense_vector\",\n",
    "                        \"dims\": 384,\n",
    "                        \"index\": True,\n",
    "                        \"similarity\": \"cosine\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Prepare docs for bulk indexing\n",
    "def create_docs(data):\n",
    "    for _, row in data.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": row[\"issue_id\"],\n",
    "            \"_source\": {\n",
    "                \"issue_id\": row[\"issue_id\"],\n",
    "                \"issue_body\": row[\"issue_body\"],\n",
    "                \"answer_body\": row[\"answer_body\"],\n",
    "                \"embedding\": row[\"embedding\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Bulk upload\n",
    "bulk(es, create_docs(grouped))\n",
    "print(\"âœ… Embeddings stored successfully in Elasticsearch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd9b4d-1aac-48e1-9e5a-e8092da52232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ee0fe-9084-492a-ad96-f659ddea060b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a287b301-c2a8-4ee9-b005-578133a983e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 23 09:46:41 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   39C    P0             28W /   70W |     741MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            6256      C   /opt/app-root/bin/python3.11            738MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21eb03fd-5651-4ac7-b465-f9ace6dc7210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available indices: ['.security-7', 'helpdesk-embeddings']\n",
      "Num of embeddings in index: 15784\n",
      "ID: 456983\n",
      "ID: 648603\n",
      "ID: 798136\n",
      "ID: 814067\n",
      "ID: 984126\n",
      "ID: 998441\n",
      "ID: 2349963\n",
      "ID: 2891909\n",
      "ID: 3052375\n",
      "ID: 3500667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/tmp/ipykernel_67/250962508.py:11: ElasticsearchWarning: this request accesses system indices: [.security-7], but in a future major version, direct access to system indices will be prevented by default\n",
      "  indices = es.indices.get_alias().keys()\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n"
     ]
    }
   ],
   "source": [
    "## for debugging/testing purposes only \n",
    "\n",
    "# elasticsearch client \n",
    "es = Elasticsearch(\n",
    "    hosts=[\"https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com\"], \n",
    "    basic_auth=('myadmin', 'newpassword123'), \n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "# view available embedding indices \n",
    "indices = es.indices.get_alias().keys()\n",
    "print(\"Available indices:\", list(indices))\n",
    "\n",
    "# view all stored embeddings \n",
    "results = es.search(\n",
    "    index=\"helpdesk-embeddings\",\n",
    "    size=10,  # adjust as needed\n",
    "    _source=[\"embedding\"]  # only return embedding field\n",
    ")\n",
    "\n",
    "# view the number of documents in the stored index \n",
    "count = es.count(index=\"helpdesk-embeddings\")[\"count\"]\n",
    "print(f\"Num of embeddings in index: {count}\")\n",
    "\n",
    "\n",
    "for doc in results[\"hits\"][\"hits\"]:\n",
    "    print(f\"ID: {doc['_id']}\")\n",
    "    # print(\"Embedding:\", doc[\"_source\"][\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4668850a-653f-4f22-9a9a-f0ce82a366dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available indices: ['.security-7', 'helpdesk-embeddings']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n",
      "/tmp/ipykernel_67/1093246816.py:15: ElasticsearchWarning: this request accesses system indices: [.security-7], but in a future major version, direct access to system indices will be prevented by default\n",
      "  indices = es.indices.get_alias().keys()\n"
     ]
    }
   ],
   "source": [
    "# delete the entire index after checking \n",
    "# ONLY RUN TO DELETE THE ENTIRE INDEX CREATED - SO THAT IT IS A CLEAN STATE IN VECTOR DB\n",
    "\n",
    "# elasticsearch client \n",
    "es = Elasticsearch(\n",
    "    hosts=[\"https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com\"], \n",
    "    basic_auth=('myadmin', 'newpassword123'), \n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "# es.indices.delete(index=\"helpdesk-embeddings\", ignore_unavailable=True)\n",
    "# print(\"Index deleted.\\n\")\n",
    "\n",
    "# view available embedding indices \n",
    "indices = es.indices.get_alias().keys()\n",
    "print(\"Available indices:\", list(indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a5b52-dad1-4f56-ba1a-8f1e79107c86",
   "metadata": {},
   "source": [
    "<h1>Retrieving Top 3 Most Relevant Embeddings from Vector DB</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e944a9a-a2eb-492d-8277-441287a299c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'dense_vector', 'dims': 384, 'index': True, 'similarity': 'cosine', 'index_options': {'type': 'int8_hnsw', 'm': 16, 'ef_construction': 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  # Force connect early to allow us to validate the connection.\n"
     ]
    }
   ],
   "source": [
    "# elasticsearch client \n",
    "es = Elasticsearch(\n",
    "    hosts=[\"https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com\"], \n",
    "    basic_auth=('myadmin', 'newpassword123'), \n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "mapping = es.indices.get_mapping(index=\"helpdesk-embeddings\")\n",
    "print(mapping[\"helpdesk-embeddings\"][\"mappings\"][\"properties\"].get(\"embedding\", \"Field not found\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b4b153-1630-46d1-97ef-f28ca7b92e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/elasticsearch/_sync/client/__init__.py:397: SecurityWarning: Connecting to 'https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com:443' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n",
      "You try to use a model that was created with version 4.1.0, however, your version is 3.1.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue ID: 814067\n",
      "Answer Body: Having a header like this one in _all_ pelican's files seems more than annoying to me. After some search, it seems that the recommended practice is to to add the notice in every file, but not doing so will not invalidate the license or change the meaning of it (<link> Anyway, I will change the LICENSE text. > After some search, it seems that the recommended practice is to to add the notice in every file, but not doing so will not invalidate the license Interesting, I did not know.\n",
      "Score: 0.79530144\n",
      "==================================================\n",
      "Issue ID: 1267992009\n",
      "Answer Body: `pelican` doesn't have a `parser.py`. This is likely from a plugin. Try removing plugins or running `pelican` with `--debug` to see which file/plugin is the issue. ![image](<link> I don't recall installing this plugin. I'm currently in dependency hell, can't get linker plugin to import a module from itself. Hey David. Were you eventually able to get everything sorted out?\n",
      "Score: 0.7677038\n",
      "==================================================\n",
      "Issue ID: 683970143\n",
      "Answer Body: Hi Michael. * `from 'pelican.utils'` indicates that it's trying to import from within Pelican â€” not Six or some other dependency * searching for `python_2_unicode_compatible` inside Pelican's code base yields nothing, so it was likely removed * searching `pelican/utils.py` history shows [where `python_2_unicode_compatible` used to be](<link> * Pelican core no longer supports Python 2.7; this is squarely a plugin-related concern * submoduled is a far cry from officially maintained, which is why we encourage folks to move to [Pelican Plugins](<link> If you would like to continue using the `pelican_toc` plugin, and you are interested in helping with its modernization and migration to the new organization, would you please open an issue in the [legacy Pelican plugins repo](<link> as noted in the [Pelican 4.5 release notes](<link>\n",
      "Score: 0.74205995\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67/2543801249.py:25: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es.search(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import urllib3\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# Disable SSL warnings\n",
    "warnings.simplefilter('ignore', InsecureRequestWarning)\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# elasticsearch client \n",
    "es = Elasticsearch(\n",
    "    hosts=[\"https://elasticsearch-sample-demo-chatbot.apps.cluster-c5xdq.c5xdq.sandbox1264.opentlc.com\"], \n",
    "    basic_auth=('myadmin', 'newpassword123'), \n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device='cpu')\n",
    "\n",
    "\n",
    "# get top 3 most relevant embeddings \n",
    "def search_embeddings(query, top_n=3):\n",
    "    # Step 1: Embed the query using the same model\n",
    "    query_embedding = model.encode(query).tolist()\n",
    "\n",
    "    # Step 2: Search the Elasticsearch index for the closest vector matches\n",
    "    response = es.search(\n",
    "        index=\"helpdesk-embeddings\",\n",
    "        body={\n",
    "            \"size\": top_n,\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"field\": \"embedding\",\n",
    "                    \"k\": top_n,\n",
    "                    \"num_candidates\": 100,\n",
    "                    \"query_vector\": query_embedding\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    hits = response[\"hits\"][\"hits\"]\n",
    "    relevant_answers = []\n",
    "\n",
    "    for hit in hits:\n",
    "        issue_id = hit[\"_source\"][\"issue_id\"]\n",
    "        answer_body = hit[\"_source\"][\"answer_body\"]\n",
    "        score = hit[\"_score\"]\n",
    "        relevant_answers.append({\n",
    "            \"issue_id\": issue_id,\n",
    "            \"answer_body\": answer_body,\n",
    "            \"score\": score\n",
    "        })\n",
    "\n",
    "    return relevant_answers\n",
    "\n",
    "user_query = \"I have an issue with Pelican license, where pelican doe not have a parser.py\"\n",
    "top_matches = search_embeddings(user_query) \n",
    "\n",
    "for match in top_matches:\n",
    "    print(f\"Issue ID: {match['issue_id']}\")\n",
    "    print(f\"Answer Body: {match['answer_body']}\")\n",
    "    print(f\"Score: {match['score']}\")\n",
    "    print(\"=\"*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39175fab-a3f5-4f58-a4a9-c7b295775b91",
   "metadata": {},
   "source": [
    "<h1>Model Inference - Prompt Construction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d82db52-2afc-47d6-9396-b8954047d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry for the confusion, but the provided context doesn't include any information related to Elasticsearch errors. However, I can still try to help you troubleshoot this issue based on common practices.\n",
      "\n",
      "The error message `BadRequestError: BadRequestError(400, 'media_type_header_exception', 'Invalid media-type value on headers [Accept, Content-Type]')` typically occurs when there's an issue with the HTTP headers sent by your client (in this case, presumably your Elasticsearch script or application). \n",
      "\n",
      "Here are a few things you could check:\n",
      "\n",
      "1. **Check Accept Header**: The `Accept` header specifies what content types the client understands. Ensure that it's set correctly. For example, if you're expecting JSON responses, it should look something like this: `Accept: application/json`.\n",
      "\n",
      "2. **Check Content-Type Header**: The `Content-Type` header tells Elasticsearch what format the data being sent is in. If you're sending data in JSON format, it should be set to `application/json`.\n",
      "\n",
      "3. **Ensure Correct Encoding**: Make sure that your request body (if any) is properly encoded in UTF-8. Some libraries handle encoding automatically, while others require manual setting.\n",
      "\n",
      "4. **Update Elasticsearch Client Library**: If you're using a third-party library to interact with Elasticsearch, ensure it's up-to-date. Older versions might have bugs causing such issues.\n",
      "\n",
      "If none of these suggestions resolve your issue, consider checking Elasticsearch's official documentation or reaching out to their community support channels for further assistance. They'd be better equipped to provide specific guidance given their expertise with their own product.\n"
     ]
    }
   ],
   "source": [
    "infer_endpoint = \"http://model-predictor.minio.svc.cluster.local:8080\" #Change infer endpoint here\n",
    "infer_url = f\"{infer_endpoint}/v1/chat/completions\"\n",
    "\n",
    "user_query = \"I have the error BadRequestError: BadRequestError(400, 'media_type_header_exception', 'Invalid media-type value on headers [Accept, Content-Type]') when running elasticsearch\"\n",
    "# Build the retrieved context\n",
    "context = \"\\n\\n---\\n\\n\".join([f\"Issue ID: {match['issue_id']}\\nAnswer: {match['answer_body']}\" for match in top_matches])\n",
    "\n",
    "# Step 2: Construct messages for /v1/chat/completions (include chain-of-thought reasoning model)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a helpful and knowledgeable support assistant. \"\n",
    "            \"Answer the user's question clearly and accurately. \"\n",
    "            \"Use the provided context from our database to support your response wherever relevant. \"\n",
    "            \"Think step by step when forming your answer, reasoning through each part of the problem before responding. \"\n",
    "            \"If the context does not contain enough information to answer the question, \"\n",
    "            \"politely let the user know and suggest alternative next steps if appropriate.\\n\\n\"\n",
    "            f\"Context:\\n{context}\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_query\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"model\",\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.3, # Controls randomness, lower temp for factuality \n",
    "    \"top_p\": 1,\n",
    "    \"n\": 1, # Number of completions to generate\n",
    "    \"repetition_penalty\": 1.1, # Penalize repeated tokens (1 = no penalty)\n",
    "    \"presence_penalty\": 0.2, # Discourage mentioning same concepts again\n",
    "    \"frequency_penalty\": 0.2, # Discourage repeating the *same words* too frequently\n",
    "    \"stream\": False # If True, stream tokens back (like a live typewriter)\n",
    "}\n",
    "\n",
    "# query LLM server\n",
    "response = requests.post(infer_url, json=payload)\n",
    "\n",
    "# prints the whole response json\n",
    "# print(response.json())\n",
    "\n",
    "output_body = response.json()\n",
    "generated_response = output_body['choices'][0]['message']['content']\n",
    "print(generated_response.strip())\n",
    "\n",
    "# add to the messages list \n",
    "messages.append({\"role\": \"system\", \"content\": generated_response.strip()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f9ece-e9cf-44e2-a8a2-73160186aee8",
   "metadata": {},
   "source": [
    "<h1>Request Function</h1>\n",
    "\n",
    "Build and submit the REST request. \n",
    "\n",
    "Note: You submit the data in the same format that you used for an ONNX inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9386f-683a-4880-b780-c40bec3ab9f8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def rest_request(prompt):\n",
    "    json_data = {\n",
    "        \"model\": \"llm\",\n",
    "        \"prompt\": [\n",
    "            prompt\n",
    "        ],\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1,\n",
    "        \"n\": 1,\n",
    "        \"stream\": False,\n",
    "        \"logprobs\": 0,\n",
    "        \"echo\": False,\n",
    "        \"stop\": [\n",
    "            \"string\"\n",
    "        ],\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"best_of\": 1,\n",
    "        \"user\": \"string\",\n",
    "        \"top_k\": -1,\n",
    "        \"ignore_eos\": False,\n",
    "        \"use_beam_search\": False,\n",
    "        \"stop_token_ids\": [\n",
    "            0\n",
    "        ],\n",
    "        \"skip_special_tokens\": True,\n",
    "        \"spaces_between_special_tokens\": True,\n",
    "        \"repetition_penalty\": 1,\n",
    "        \"min_p\": 0,\n",
    "        \"include_stop_str_in_output\": False,\n",
    "        \"length_penalty\": 1\n",
    "    }\n",
    "\n",
    "    response = requests.post(infer_url, json=json_data, verify=False)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad16ac-23da-48bd-9796-f8e4cacae981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = rest_request(\"What accelerators are supported in openshift AI?\")\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd2c336d-44a7-47cc-81ea-ab14b980fc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!curl http://model-predictor.minio.svc.cluster.local:8080/health"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
