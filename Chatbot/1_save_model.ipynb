{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160daf33-7f69-4587-b30d-b87d9038a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub)\n",
      "  Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Downloading huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m189.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, hf-xet, fsspec, filelock, huggingface_hub\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.3 huggingface_hub-0.32.4 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a72a0a7-eeb3-4654-9a2c-92b65508967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun  5 08:25:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   27C    P8             23W /  300W |       1MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1276f926-0395-4f9c-ba05-96b3e626a92d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib64/python3.11/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-25.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9609dc7b-c620-419f-8787-ea92555bd551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.2.2 (from -r requirements.txt (line 2))\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 3))\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting seaborn==0.13.2 (from -r requirements.txt (line 6))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting matplotlib==3.8.4 (from -r requirements.txt (line 7))\n",
      "  Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting missingno==0.5.2 (from -r requirements.txt (line 8))\n",
      "  Downloading missingno-0.5.2-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting scipy==1.13.0 (from -r requirements.txt (line 11))\n",
      "  Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting statsmodels==0.14.2 (from -r requirements.txt (line 12))\n",
      "  Downloading statsmodels-0.14.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting scikit-learn==1.4.2 (from -r requirements.txt (line 15))\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting nltk==3.8.1 (from -r requirements.txt (line 18))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sentence-transformers>=2.5.0 (from -r requirements.txt (line 19))\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers==4.40.1 (from -r requirements.txt (line 20))\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "Collecting accelerate==0.30.1 (from -r requirements.txt (line 21))\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting streamlit==1.32.2 (from -r requirements.txt (line 25))\n",
      "  Downloading streamlit-1.32.2-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting elasticsearch==8.10.0 (from -r requirements.txt (line 28))\n",
      "  Downloading elasticsearch-8.10.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting requests==2.31.0 (from -r requirements.txt (line 31))\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting urllib3==2.2.1 (from -r requirements.txt (line 32))\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting tqdm==4.66.2 (from -r requirements.txt (line 35))\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting boto3==1.34.79 (from -r requirements.txt (line 38))\n",
      "  Downloading boto3-1.34.79-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore==1.34.79 (from -r requirements.txt (line 39))\n",
      "  Downloading botocore-1.34.79-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas==2.2.2->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.2->-r requirements.txt (line 2))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.2->-r requirements.txt (line 2))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.8.4->-r requirements.txt (line 7))\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.8.4->-r requirements.txt (line 7))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.8.4->-r requirements.txt (line 7))\n",
      "  Downloading fonttools-4.58.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.8.4->-r requirements.txt (line 7))\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib==3.8.4->-r requirements.txt (line 7)) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib==3.8.4->-r requirements.txt (line 7))\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.8.4->-r requirements.txt (line 7))\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels==0.14.2->-r requirements.txt (line 12))\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn==1.4.2->-r requirements.txt (line 15))\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.4.2->-r requirements.txt (line 15))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click (from nltk==3.8.1->-r requirements.txt (line 18))\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk==3.8.1->-r requirements.txt (line 18))\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.40.1->-r requirements.txt (line 20)) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.40.1->-r requirements.txt (line 20)) (0.32.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.40.1->-r requirements.txt (line 20)) (6.0.2)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.1->-r requirements.txt (line 20))\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.40.1->-r requirements.txt (line 20))\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.11/site-packages (from accelerate==0.30.1->-r requirements.txt (line 21)) (7.0.0)\n",
      "Collecting torch>=1.10.0 (from accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib==3.8.4->-r requirements.txt (line 7))\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.8.4->-r requirements.txt (line 7))\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<5,>=3.20 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/app-root/lib64/python3.11/site-packages (from streamlit==1.32.2->-r requirements.txt (line 25)) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/app-root/lib64/python3.11/site-packages (from streamlit==1.32.2->-r requirements.txt (line 25)) (3.1.44)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/app-root/lib64/python3.11/site-packages (from streamlit==1.32.2->-r requirements.txt (line 25)) (6.4.2)\n",
      "Collecting watchdog>=2.1.5 (from streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 31)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 31)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 31)) (2025.1.31)\n",
      "Collecting elastic-transport<9,>=8 (from elasticsearch==8.10.0->-r requirements.txt (line 28))\n",
      "  Downloading elastic_transport-8.17.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3==1.34.79->-r requirements.txt (line 38))\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3==1.34.79->-r requirements.txt (line 38))\n",
      "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from altair<6,>=4.0->streamlit==1.32.2->-r requirements.txt (line 25)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/app-root/lib64/python3.11/site-packages (from altair<6,>=4.0->streamlit==1.32.2->-r requirements.txt (line 25)) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading narwhals-1.41.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/app-root/lib64/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.32.2->-r requirements.txt (line 25)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/app-root/lib64/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.32.2->-r requirements.txt (line 25)) (5.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1->-r requirements.txt (line 20)) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1->-r requirements.txt (line 20)) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 2)) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.11/site-packages (from rich<14,>=10.14.0->streamlit==1.32.2->-r requirements.txt (line 25)) (2.19.1)\n",
      "INFO: pip is looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sentence-transformers>=2.5.0 (from -r requirements.txt (line 19))\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-4.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is still looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.32.2->-r requirements.txt (line 25)) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.32.2->-r requirements.txt (line 25)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.32.2->-r requirements.txt (line 25)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.32.2->-r requirements.txt (line 25)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.32.2->-r requirements.txt (line 25)) (0.23.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.32.2->-r requirements.txt (line 25))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/app-root/lib64/python3.11/site-packages (from triton==3.3.1->torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21)) (75.8.2)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.30.1->-r requirements.txt (line 21))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m173.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m225.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m213.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
      "Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m212.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m225.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m233.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m392.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m229.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "Downloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m238.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Downloading elasticsearch-8.10.0-py3-none-any.whl (414 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading boto3-1.34.79-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.34.79-py3-none-any.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m216.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m519.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading elastic_transport-8.17.1-py3-none-any.whl (64 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m222.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m230.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m273.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
      "Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m237.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m471.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading narwhals-1.41.0-py3-none-any.whl (357 kB)\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m226.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m462.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m221.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m205.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m222.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m225.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m511.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m223.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m221.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m430.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m152.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m193.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m224.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m182.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m225.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m228.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m205.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m486.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m155.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, nvidia-cusparselt-cu12, mpmath, watchdog, urllib3, tzdata, triton, tqdm, toml, threadpoolctl, tenacity, sympy, safetensors, regex, pyparsing, pyarrow, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, narwhals, mdurl, kiwisolver, joblib, jmespath, fonttools, cycler, click, cachetools, blinker, scipy, requests, pydeck, patsy, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, markdown-it-py, elastic-transport, contourpy, botocore, statsmodels, scikit-learn, s3transfer, rich, nvidia-cusolver-cu12, matplotlib, elasticsearch, torch, tokenizers, seaborn, boto3, altair, transformers, streamlit, missingno, accelerate, sentence-transformers\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]t-cu12]\n",
      "\u001b[2K    Found existing installation: urllib3 2.3.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling urllib3-2.3.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/70\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.3.0━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/70\u001b[0m [urllib3]\n",
      "\u001b[2K  Attempting uninstall: tqdm0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/70\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/70\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/70\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/70\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: packaging90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/70\u001b[0m [pillow]]g]\n",
      "\u001b[2K    Found existing installation: packaging 24.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/70\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-24.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/70\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-24.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/70\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: requests0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/70\u001b[0m [scipy]ols]las-cu12]u12]2]\n",
      "\u001b[2K    Found existing installation: requests 2.32.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/70\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling requests-2.32.3:1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/70\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/70\u001b[0m [scipy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70/70\u001b[0m [sentence-transformers]sformers]]r-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-0.30.1 altair-5.5.0 blinker-1.9.0 boto3-1.34.79 botocore-1.34.79 cachetools-5.5.2 click-8.2.1 contourpy-1.3.2 cycler-0.12.1 elastic-transport-8.17.1 elasticsearch-8.10.0 fonttools-4.58.1 jmespath-1.0.1 joblib-1.5.1 kiwisolver-1.4.8 markdown-it-py-3.0.0 matplotlib-3.8.4 mdurl-0.1.2 missingno-0.5.2 mpmath-1.3.0 narwhals-1.41.0 networkx-3.5 nltk-3.8.1 numpy-1.26.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 packaging-23.2 pandas-2.2.2 patsy-1.0.1 pillow-10.4.0 protobuf-4.25.8 pyarrow-20.0.0 pydeck-0.9.1 pyparsing-3.2.3 pytz-2025.2 regex-2024.11.6 requests-2.31.0 rich-13.9.4 s3transfer-0.10.4 safetensors-0.5.3 scikit-learn-1.4.2 scipy-1.13.0 seaborn-0.13.2 sentence-transformers-3.1.1 statsmodels-0.14.2 streamlit-1.32.2 sympy-1.14.0 tenacity-8.5.0 threadpoolctl-3.6.0 tokenizers-0.19.1 toml-0.10.2 torch-2.7.1 tqdm-4.66.2 transformers-4.40.1 triton-3.3.1 tzdata-2025.2 urllib3-2.2.1 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6e7b3-4c40-4289-b540-99b62bf213de",
   "metadata": {},
   "source": [
    "## Snapshot Download of Granite Model\n",
    "\n",
    "Download full repo to prepare for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b727f656-e9c4-4eab-a134-fe26f369d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️  Downloading model 'ibm-granite/granite-3.2-8b-instruct' to './granite-3.2-8b-instruct' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 15 files: 100%|██████████| 15/15 [03:13<00:00, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model downloaded to: /opt/app-root/src/SEAK_AI/Chatbot/granite-3.2-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading granite model\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_id = \"ibm-granite/granite-3.2-8b-instruct\"\n",
    "local_path = \"./granite-3.2-8b-instruct\"\n",
    "\n",
    "print(f\"⬇️  Downloading model '{model_id}' to '{local_path}' ...\")\n",
    "local_path = snapshot_download(repo_id=model_id, local_dir=local_path, local_dir_use_symlinks=False)\n",
    "print(f\"✅ Model downloaded to: {local_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86219291-a816-4f92-84d0-989a77068e92",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863e93c9-7188-4d88-a781-19cb93b0b940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 21 02:14:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   41C    P0             28W /   70W |    1075MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2822      C   /opt/app-root/bin/python3.11           1072MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9507bbfc-cb55-4c92-a70b-26edad39e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 02:14:49.029294: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-21 02:14:49.045673: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745201689.065932    3830 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745201689.072223    3830 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745201689.087737    3830 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745201689.087755    3830 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745201689.087757    3830 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745201689.087759    3830 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-21 02:14:49.093028: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you better than chatgpt?\n",
      "\n",
      "ChatGPT is a model from OpenAI, while I am a model from IBM, specifically designed for business use cases. Each model has its own strengths and is fine-tuned for different types of tasks. I specialize in handling enterprise-level data and transactions securely and efficiently, providing accurate responses in a business context.\n",
      "\n",
      "To provide a more direct comparison, ChatGPT is known for its versatility in generating human-like text across a wide range of topics, making it suitable for conversational AI applications. Meanwhile, my primary focus is on delivering precise, domain-specific responses\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"granite-3.2-8b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Convert your chat-style messages into a single prompt string\n",
    "prompt = \"Are you better than chatgpt\"\n",
    "\n",
    "response = pipe(prompt, max_new_tokens=128, do_sample=True)\n",
    "print(response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9862cd4-af18-4fa9-8497-0e865e158c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 21 02:17:01 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   45C    P0             44W /   70W |   13401MiB /  15360MiB |     72%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2822      C   /opt/app-root/bin/python3.11           1072MiB |\n",
      "|    0   N/A  N/A            3830      C   /opt/app-root/bin/python3.11          12326MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi # Can see from here that model has been loaded into GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4525dc5-68a3-447b-b96e-4a9bde302d6b",
   "metadata": {},
   "source": [
    "## Saving model in Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4587e5b-3677-4ebc-8839-ee50ec0b036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo-chatbot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Retrieve AWS credentials and S3 connection details from environment variables\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')\n",
    "\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c2c818-f93a-4fce-aef0-89360e3ad7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading granite-3.2-8b-instruct/vocab.json to s3://demo-chatbot/models/granite-model/vocab.json\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/vocab.json\n",
      "Uploading granite-3.2-8b-instruct/merges.txt to s3://demo-chatbot/models/granite-model/merges.txt\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/merges.txt\n",
      "Uploading granite-3.2-8b-instruct/model-00003-of-00004.safetensors to s3://demo-chatbot/models/granite-model/model-00003-of-00004.safetensors\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/model-00003-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/model.safetensors.index.json to s3://demo-chatbot/models/granite-model/model.safetensors.index.json\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/model.safetensors.index.json\n",
      "Uploading granite-3.2-8b-instruct/model-00002-of-00004.safetensors to s3://demo-chatbot/models/granite-model/model-00002-of-00004.safetensors\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/model-00002-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/model-00001-of-00004.safetensors to s3://demo-chatbot/models/granite-model/model-00001-of-00004.safetensors\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/model-00001-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/generation_config.json to s3://demo-chatbot/models/granite-model/generation_config.json\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/generation_config.json\n",
      "Uploading granite-3.2-8b-instruct/tokenizer.json to s3://demo-chatbot/models/granite-model/tokenizer.json\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/tokenizer.json\n",
      "Uploading granite-3.2-8b-instruct/model-00004-of-00004.safetensors to s3://demo-chatbot/models/granite-model/model-00004-of-00004.safetensors\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/model-00004-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/config.json to s3://demo-chatbot/models/granite-model/config.json\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/config.json\n",
      "Uploading granite-3.2-8b-instruct/special_tokens_map.json to s3://demo-chatbot/models/granite-model/special_tokens_map.json\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/special_tokens_map.json\n",
      "Uploading granite-3.2-8b-instruct/tokenizer_config.json to s3://demo-chatbot/models/granite-model/tokenizer_config.json\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/tokenizer_config.json\n",
      "Uploading granite-3.2-8b-instruct/README.md to s3://demo-chatbot/models/granite-model/README.md\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/README.md\n",
      "Uploading granite-3.2-8b-instruct/added_tokens.json to s3://demo-chatbot/models/granite-model/added_tokens.json\n",
      "✅ Uploaded to s3://demo-chatbot/models/granite-model/added_tokens.json\n",
      "✅ Upload completed.\n",
      "\n",
      "📦 Objects in S3 under 'models/granite-model':\n",
      "models/granite-model/README.md\n",
      "models/granite-model/added_tokens.json\n",
      "models/granite-model/config.json\n",
      "models/granite-model/generation_config.json\n",
      "models/granite-model/merges.txt\n",
      "models/granite-model/model-00001-of-00004.safetensors\n",
      "models/granite-model/model-00002-of-00004.safetensors\n",
      "models/granite-model/model-00003-of-00004.safetensors\n",
      "models/granite-model/model-00004-of-00004.safetensors\n",
      "models/granite-model/model.safetensors.index.json\n",
      "models/granite-model/special_tokens_map.json\n",
      "models/granite-model/tokenizer.json\n",
      "models/granite-model/tokenizer_config.json\n",
      "models/granite-model/vocab.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "\n",
    "\n",
    "local_model_dir = \"granite-3.2-8b-instruct\"  # Path to your local model directory\n",
    "s3_prefix = \"models/granite-model\"   # Desired path in S3 bucket\n",
    "\n",
    "# === Initialize session and resource ===\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "\n",
    "def should_upload(file_path):\n",
    "    \"\"\"\n",
    "    Determine if a file should be uploaded (skip .git and hidden files).\n",
    "    \"\"\"\n",
    "    # Skip hidden files and folders (like .git, .DS_Store)\n",
    "    parts = file_path.split(os.sep)\n",
    "    for part in parts:\n",
    "        if part.startswith('.'):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def upload_file_to_s3(local_file_path, s3_key):\n",
    "    \"\"\"\n",
    "    Uploads a single file to S3.\n",
    "    \"\"\"\n",
    "    print(f\"Uploading {local_file_path} to s3://{bucket_name}/{s3_key}\")\n",
    "    bucket.upload_file(local_file_path, s3_key)\n",
    "    print(f\"✅ Uploaded to s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "\n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    \"\"\"\n",
    "    Recursively uploads a directory to S3, skipping unwanted files.\n",
    "    \"\"\"\n",
    "    found_files = False\n",
    "\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        # Modify dirs in-place to skip hidden folders\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "\n",
    "        for filename in files:\n",
    "            if filename.startswith('.'):\n",
    "                continue  # Skip hidden files\n",
    "\n",
    "            local_path = os.path.join(root, filename)\n",
    "            if not should_upload(local_path):\n",
    "                continue  # Skip unwanted files\n",
    "\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            upload_file_to_s3(local_path, s3_key)\n",
    "            found_files = True\n",
    "\n",
    "    if not found_files:\n",
    "        print(\"🚨 No valid files found to upload. Check your directory and filters!\")\n",
    "    else:\n",
    "        print(\"✅ Upload completed.\")\n",
    "\n",
    "\n",
    "def list_objects(prefix):\n",
    "    \"\"\"\n",
    "    Lists all objects in the S3 bucket with a given prefix.\n",
    "    \"\"\"\n",
    "    print(f\"\\n📦 Objects in S3 under '{prefix}':\")\n",
    "    for obj in bucket.objects.filter(Prefix=prefix):\n",
    "        print(obj.key)\n",
    "\n",
    "\n",
    "# === Run Upload ===\n",
    "upload_directory_to_s3(local_model_dir, s3_prefix)\n",
    "\n",
    "# === List uploaded objects ===\n",
    "list_objects(s3_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ab303d-718d-472f-9300-c7e5318ab8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='ibm-granite/granite-3.2-8b-instruct', vocab_size=49152, model_max_length=9223372036854775807, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<|end_of_text|>', 'eos_token': '<|end_of_text|>', 'unk_token': '<|end_of_text|>', 'pad_token': '<|end_of_text|>', 'additional_special_tokens': ['<|start_of_role|>', '<|end_of_role|>', '<|tool_call|>']}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<fim_prefix>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<fim_middle>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<fim_suffix>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<fim_pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t5: AddedToken(\"<filename>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t6: AddedToken(\"<gh_stars>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t7: AddedToken(\"<issue_start>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t8: AddedToken(\"<issue_comment>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t9: AddedToken(\"<issue_closed>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t10: AddedToken(\"<jupyter_start>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t11: AddedToken(\"<jupyter_text>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t12: AddedToken(\"<jupyter_code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t13: AddedToken(\"<jupyter_output>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t14: AddedToken(\"<empty_output>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t15: AddedToken(\"<commit_before>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t16: AddedToken(\"<commit_msg>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t17: AddedToken(\"<commit_after>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t18: AddedToken(\"<reponame>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t49152: AddedToken(\"<|start_of_role|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t49153: AddedToken(\"<|end_of_role|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t49154: AddedToken(\"<|tool_call|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download and cache the tokenizer to a local folder\n",
    "AutoTokenizer.from_pretrained(\"ibm-granite/granite-3.2-8b-instruct\", cache_dir=\"./tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78543061-6481-4c51-99be-e6c4796c348c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfa48a-e0a5-4e64-8eae-344549a6a08f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
