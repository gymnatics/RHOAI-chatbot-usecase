{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "160daf33-7f69-4587-b30d-b87d9038a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/app-root/lib64/python3.11/site-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->huggingface_hub) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad765da3-1c0a-4e20-a0d8-0270e37115d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nabei-tengteng\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a72a0a7-eeb3-4654-9a2c-92b65508967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 21 02:14:38 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   41C    P0             28W /   70W |    1075MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2822      C   /opt/app-root/bin/python3.11           1072MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1276f926-0395-4f9c-ba05-96b3e626a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib64/python3.11/site-packages (25.0.1)\n",
      "Requirement already satisfied: boto3 in /opt/app-root/lib64/python3.11/site-packages (1.37.34)\n",
      "Requirement already satisfied: botocore in /opt/app-root/lib64/python3.11/site-packages (1.37.34)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib64/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/app-root/lib64/python3.11/site-packages (from boto3) (0.11.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib64/python3.11/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/app-root/lib64/python3.11/site-packages (from botocore) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9609dc7b-c620-419f-8787-ea92555bd551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 13)) (1.6.1)\n",
      "Requirement already satisfied: nltk in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 14)) (3.9.1)\n",
      "Requirement already satisfied: sentence-transformers in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 17)) (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 18)) (4.51.3)\n",
      "Requirement already satisfied: accelerate in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 19)) (1.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 25)) (4.67.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 26)) (1.1.0)\n",
      "Requirement already satisfied: langchain in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 29)) (0.1.9)\n",
      "Requirement already satisfied: torch in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 32)) (2.6.0)\n",
      "Requirement already satisfied: streamlit in /opt/app-root/lib64/python3.11/site-packages (from -r requirements.txt (line 35)) (1.44.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 13)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 13)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 13)) (3.6.0)\n",
      "Requirement already satisfied: click in /opt/app-root/lib64/python3.11/site-packages (from nltk->-r requirements.txt (line 14)) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/app-root/lib64/python3.11/site-packages (from nltk->-r requirements.txt (line 14)) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers->-r requirements.txt (line 17)) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers->-r requirements.txt (line 17)) (11.2.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/app-root/lib64/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (0.5.3)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.11/site-packages (from accelerate->-r requirements.txt (line 19)) (6.1.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (2.11.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/app-root/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 29)) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 32)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 32)) (1.3.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (5.5.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (19.0.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/app-root/lib64/python3.11/site-packages (from streamlit->-r requirements.txt (line 35)) (6.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 29)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 29)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 29)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 29)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 29)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 29)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 29)) (1.18.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/app-root/lib64/python3.11/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 35)) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /opt/app-root/lib64/python3.11/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 35)) (1.35.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/app-root/lib64/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 29)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/app-root/lib64/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 29)) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/app-root/lib64/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 35)) (4.0.12)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/app-root/lib64/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 29)) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain->-r requirements.txt (line 29)) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/app-root/lib64/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain->-r requirements.txt (line 29)) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/app-root/lib64/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain->-r requirements.txt (line 29)) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 29)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/app-root/lib64/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 29)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/app-root/lib64/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 29)) (0.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 32)) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 18)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 18)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 18)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 18)) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/app-root/lib64/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 29)) (3.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/app-root/lib64/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 35)) (5.0.2)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain->-r requirements.txt (line 29)) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain->-r requirements.txt (line 29)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/app-root/lib64/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain->-r requirements.txt (line 29)) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 35)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 35)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 35)) (0.22.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/app-root/lib64/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 29)) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/app-root/lib64/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain->-r requirements.txt (line 29)) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6e7b3-4c40-4289-b540-99b62bf213de",
   "metadata": {},
   "source": [
    "## Snapshot Download of Granite Model\n",
    "\n",
    "Download full repo to prepare for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b727f656-e9c4-4eab-a134-fe26f369d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è  Downloading model 'ibm-granite/granite-3.2-8b-instruct' to './granite-3.2-8b-instruct' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/huggingface_hub/file_download.py:933: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n",
      "Fetching 15 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 21605.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model downloaded to: /opt/app-root/src/rag-with-elasticsearch/granite-3.2-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading granite model\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_id = \"ibm-granite/granite-3.2-8b-instruct\"\n",
    "local_path = \"./granite-3.2-8b-instruct\"\n",
    "\n",
    "print(f\"‚¨áÔ∏è  Downloading model '{model_id}' to '{local_path}' ...\")\n",
    "local_path = snapshot_download(repo_id=model_id, local_dir=local_path, local_dir_use_symlinks=False)\n",
    "print(f\"‚úÖ Model downloaded to: {local_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed40e34-6afd-4737-801d-1bc8dfd6e17e",
   "metadata": {},
   "source": [
    "## Quantizing Granite Model\n",
    "\n",
    "Helps to reduce memory and hardware requirements of granite model (albeit with a small accuracy loss).\n",
    "\n",
    "### **Cancelled because quantization is not supported for granite using GPU yet**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6574abd1-9a1b-4bd6-b2e0-d318b9469fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from awq import AutoAWQForCausalLM\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# model_path = \"./granite-3.2-8b-instruct\"\n",
    "# output_path = \"./granite-8b-awq-int8\"\n",
    "\n",
    "# # Load model and tokenizer\n",
    "# model = AutoAWQForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# # INT8 quantization\n",
    "# model.quantize(\n",
    "#     bits=8,                  # ‚úÖ INT8\n",
    "#     sym=True,                # Symmetric quantization\n",
    "#     per_channel=True,        # Higher accuracy\n",
    "#     damp_percent=0.01,       # Optional stabilization\n",
    "#     group_size=128           # Same structure as GPTQ\n",
    "# )\n",
    "\n",
    "# # Save the quantized model\n",
    "# model.save_quantized(output_path)\n",
    "# tokenizer.save_pretrained(output_path)\n",
    "\n",
    "# print(f\"‚úÖ AWQ INT8 quantized model saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86219291-a816-4f92-84d0-989a77068e92",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863e93c9-7188-4d88-a781-19cb93b0b940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 21 02:14:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   41C    P0             28W /   70W |    1075MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2822      C   /opt/app-root/bin/python3.11           1072MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9507bbfc-cb55-4c92-a70b-26edad39e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 02:14:49.029294: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-21 02:14:49.045673: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745201689.065932    3830 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745201689.072223    3830 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745201689.087737    3830 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745201689.087755    3830 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745201689.087757    3830 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745201689.087759    3830 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-21 02:14:49.093028: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.15it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you better than chatgpt?\n",
      "\n",
      "ChatGPT is a model from OpenAI, while I am a model from IBM, specifically designed for business use cases. Each model has its own strengths and is fine-tuned for different types of tasks. I specialize in handling enterprise-level data and transactions securely and efficiently, providing accurate responses in a business context.\n",
      "\n",
      "To provide a more direct comparison, ChatGPT is known for its versatility in generating human-like text across a wide range of topics, making it suitable for conversational AI applications. Meanwhile, my primary focus is on delivering precise, domain-specific responses\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"granite-3.2-8b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Convert your chat-style messages into a single prompt string\n",
    "prompt = \"Are you better than chatgpt\"\n",
    "\n",
    "response = pipe(prompt, max_new_tokens=128, do_sample=True)\n",
    "print(response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9862cd4-af18-4fa9-8497-0e865e158c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 21 02:17:01 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   45C    P0             44W /   70W |   13401MiB /  15360MiB |     72%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2822      C   /opt/app-root/bin/python3.11           1072MiB |\n",
      "|    0   N/A  N/A            3830      C   /opt/app-root/bin/python3.11          12326MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi # Can see from here that model has been loaded into GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64977b75-2205-4463-b265-466549d135f9",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e7f534c-c728-482e-9db8-fe9d4f0e1323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nabei-tengteng\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6134b45-95b2-436b-a544-3db1b6590d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "\n",
    "# Set your variables (do NOT hardcode tokens in real production ‚Äî use dotenv or CI secrets)\n",
    "os.environ[\"HF_USERNAME\"] = \"nabei-tengteng\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a933d922-767e-4299-9757-c2244913808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ[\"HF_USERNAME\"]\n",
    "token = os.environ[\"HF_TOKEN\"]\n",
    "\n",
    "# git_repo = f\"https://{username}:{token}@huggingface.co/ibm-granite/granite-3.2-8b-instruct\"\n",
    "# !git clone $git_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4525dc5-68a3-447b-b96e-4a9bde302d6b",
   "metadata": {},
   "source": [
    "## Saving model in Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4587e5b-3677-4ebc-8839-ee50ec0b036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpdesk-chatbot-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Retrieve AWS credentials and S3 connection details from environment variables\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')\n",
    "\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c2c818-f93a-4fce-aef0-89360e3ad7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading granite-3.2-8b-instruct/added_tokens.json to s3://helpdesk-chatbot-data/models/granite-model/added_tokens.json\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/added_tokens.json\n",
      "Uploading granite-3.2-8b-instruct/merges.txt to s3://helpdesk-chatbot-data/models/granite-model/merges.txt\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/merges.txt\n",
      "Uploading granite-3.2-8b-instruct/model-00002-of-00004.safetensors to s3://helpdesk-chatbot-data/models/granite-model/model-00002-of-00004.safetensors\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model-00002-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/README.md to s3://helpdesk-chatbot-data/models/granite-model/README.md\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/README.md\n",
      "Uploading granite-3.2-8b-instruct/tokenizer_config.json to s3://helpdesk-chatbot-data/models/granite-model/tokenizer_config.json\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/tokenizer_config.json\n",
      "Uploading granite-3.2-8b-instruct/generation_config.json to s3://helpdesk-chatbot-data/models/granite-model/generation_config.json\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/generation_config.json\n",
      "Uploading granite-3.2-8b-instruct/model.safetensors.index.json to s3://helpdesk-chatbot-data/models/granite-model/model.safetensors.index.json\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model.safetensors.index.json\n",
      "Uploading granite-3.2-8b-instruct/model-00004-of-00004.safetensors to s3://helpdesk-chatbot-data/models/granite-model/model-00004-of-00004.safetensors\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model-00004-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/model-00003-of-00004.safetensors to s3://helpdesk-chatbot-data/models/granite-model/model-00003-of-00004.safetensors\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model-00003-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/tokenizer.json to s3://helpdesk-chatbot-data/models/granite-model/tokenizer.json\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/tokenizer.json\n",
      "Uploading granite-3.2-8b-instruct/model-00001-of-00004.safetensors to s3://helpdesk-chatbot-data/models/granite-model/model-00001-of-00004.safetensors\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/model-00001-of-00004.safetensors\n",
      "Uploading granite-3.2-8b-instruct/vocab.json to s3://helpdesk-chatbot-data/models/granite-model/vocab.json\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/vocab.json\n",
      "Uploading granite-3.2-8b-instruct/special_tokens_map.json to s3://helpdesk-chatbot-data/models/granite-model/special_tokens_map.json\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/special_tokens_map.json\n",
      "Uploading granite-3.2-8b-instruct/config.json to s3://helpdesk-chatbot-data/models/granite-model/config.json\n",
      "‚úÖ Uploaded to s3://helpdesk-chatbot-data/models/granite-model/config.json\n",
      "‚úÖ Upload completed.\n",
      "\n",
      "üì¶ Objects in S3 under 'models/granite-model':\n",
      "models/granite-model/README.md\n",
      "models/granite-model/added_tokens.json\n",
      "models/granite-model/config.json\n",
      "models/granite-model/generation_config.json\n",
      "models/granite-model/merges.txt\n",
      "models/granite-model/model-00001-of-00004.safetensors\n",
      "models/granite-model/model-00002-of-00004.safetensors\n",
      "models/granite-model/model-00003-of-00004.safetensors\n",
      "models/granite-model/model-00004-of-00004.safetensors\n",
      "models/granite-model/model.safetensors.index.json\n",
      "models/granite-model/special_tokens_map.json\n",
      "models/granite-model/tokenizer.json\n",
      "models/granite-model/tokenizer_config.json\n",
      "models/granite-model/vocab.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "\n",
    "\n",
    "local_model_dir = \"granite-3.2-8b-instruct\"  # Path to your local model directory\n",
    "s3_prefix = \"models/granite-model\"   # Desired path in S3 bucket\n",
    "\n",
    "# === Initialize session and resource ===\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "\n",
    "def should_upload(file_path):\n",
    "    \"\"\"\n",
    "    Determine if a file should be uploaded (skip .git and hidden files).\n",
    "    \"\"\"\n",
    "    # Skip hidden files and folders (like .git, .DS_Store)\n",
    "    parts = file_path.split(os.sep)\n",
    "    for part in parts:\n",
    "        if part.startswith('.'):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def upload_file_to_s3(local_file_path, s3_key):\n",
    "    \"\"\"\n",
    "    Uploads a single file to S3.\n",
    "    \"\"\"\n",
    "    print(f\"Uploading {local_file_path} to s3://{bucket_name}/{s3_key}\")\n",
    "    bucket.upload_file(local_file_path, s3_key)\n",
    "    print(f\"‚úÖ Uploaded to s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "\n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    \"\"\"\n",
    "    Recursively uploads a directory to S3, skipping unwanted files.\n",
    "    \"\"\"\n",
    "    found_files = False\n",
    "\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        # Modify dirs in-place to skip hidden folders\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "\n",
    "        for filename in files:\n",
    "            if filename.startswith('.'):\n",
    "                continue  # Skip hidden files\n",
    "\n",
    "            local_path = os.path.join(root, filename)\n",
    "            if not should_upload(local_path):\n",
    "                continue  # Skip unwanted files\n",
    "\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            upload_file_to_s3(local_path, s3_key)\n",
    "            found_files = True\n",
    "\n",
    "    if not found_files:\n",
    "        print(\"üö® No valid files found to upload. Check your directory and filters!\")\n",
    "    else:\n",
    "        print(\"‚úÖ Upload completed.\")\n",
    "\n",
    "\n",
    "def list_objects(prefix):\n",
    "    \"\"\"\n",
    "    Lists all objects in the S3 bucket with a given prefix.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüì¶ Objects in S3 under '{prefix}':\")\n",
    "    for obj in bucket.objects.filter(Prefix=prefix):\n",
    "        print(obj.key)\n",
    "\n",
    "\n",
    "# === Run Upload ===\n",
    "upload_directory_to_s3(local_model_dir, s3_prefix)\n",
    "\n",
    "# === List uploaded objects ===\n",
    "list_objects(s3_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ab303d-718d-472f-9300-c7e5318ab8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='ibm-granite/granite-3.2-8b-instruct', vocab_size=49152, model_max_length=9223372036854775807, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<|end_of_text|>', 'eos_token': '<|end_of_text|>', 'unk_token': '<|end_of_text|>', 'pad_token': '<|end_of_text|>', 'additional_special_tokens': ['<|start_of_role|>', '<|end_of_role|>', '<|tool_call|>']}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<fim_prefix>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<fim_middle>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<fim_suffix>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<fim_pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t5: AddedToken(\"<filename>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t6: AddedToken(\"<gh_stars>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t7: AddedToken(\"<issue_start>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t8: AddedToken(\"<issue_comment>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t9: AddedToken(\"<issue_closed>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t10: AddedToken(\"<jupyter_start>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t11: AddedToken(\"<jupyter_text>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t12: AddedToken(\"<jupyter_code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t13: AddedToken(\"<jupyter_output>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t14: AddedToken(\"<empty_output>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t15: AddedToken(\"<commit_before>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t16: AddedToken(\"<commit_msg>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t17: AddedToken(\"<commit_after>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t18: AddedToken(\"<reponame>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t49152: AddedToken(\"<|start_of_role|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t49153: AddedToken(\"<|end_of_role|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t49154: AddedToken(\"<|tool_call|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download and cache the tokenizer to a local folder\n",
    "AutoTokenizer.from_pretrained(\"ibm-granite/granite-3.2-8b-instruct\", cache_dir=\"./tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78543061-6481-4c51-99be-e6c4796c348c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfa48a-e0a5-4e64-8eae-344549a6a08f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
